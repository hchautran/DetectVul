{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Edwin372/Thesis/blob/main/Vudenc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E4z66vGHOFS",
        "outputId": "62cf83d7-fc66-455c-a08e-c0356483c63c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'VulnerabilityDetection' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/LauraWartschinski/VulnerabilityDetection.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmxR3QtnvJM8",
        "outputId": "5158ac89-02fc-4c54-bdb0-ef6adfb25213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.9.3)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E3_ZpOcI9sGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7695c42e-d126-4589-dba2-df627d46b761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/VulnerabilityDetection/Code/w2v': No such file or directory\n",
            "mv: cannot stat '/content/VulnerabilityDetection/Code/myutils.py': No such file or directory\n",
            "mv: cannot stat '/content/VulnerabilityDetection/Code/data': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mv /content/VulnerabilityDetection/Code/w2v /content\n",
        "!mv /content/VulnerabilityDetection/Code/myutils.py /content\n",
        "!mv /content/VulnerabilityDetection/Code/data /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK7yJDdr_c9A",
        "outputId": "caeb4fd2-d6ab-4548-e40a-ef27d00a1e70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/w2v/othermodels.rar\n",
            "\n",
            "\n",
            "Would you like to replace the existing file /content/w2v/word2vec_withoutString10-1-200.model\n",
            "6635437 bytes, modified on 2019-11-06 08:31\n",
            "with a new one\n",
            "6635437 bytes, modified on 2019-11-06 08:31\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit A\n",
            "\n",
            "Extracting  /content/w2v/word2vec_withoutString10-1-200.model            \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString10-5-200.model            \b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString10-10-200.model           \b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString10-30-200.model           \b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString10-50-200.model           \b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString10-100-200.model          \b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString10-300-200.model          \b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-1-200.model          \b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-5-200.model          \b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-10-200.model         \b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-30-200.model         \b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-50-200.model         \b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-100-200.model        \b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-300-200.model        \b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-500-200.model        \b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-1-200.model               \b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-5-200.model               \b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-10-200.model              \b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-30-200.model              \b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-50-200.model              \b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-100-200.model             \b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-200-200.model             \b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-300-200.model             \b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-400-200.model             \b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString5000-1-200.model             \b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString5000-5-200.model             \b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString5000-10-200.model            \b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString5000-30-200.model            \b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString5000-50-200.model            \b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString5000-100-200.model           \b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString5000-300-200.model           \b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ],
      "source": [
        "!unrar e /content/w2v/othermodels.rar /content/w2v"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar e /content/w2v/pythontraining_withString.rar /content/w2v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ooNq5G2xPxU",
        "outputId": "2fbb71ce-3e5d-43d5-85c4-7b41be711884"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/w2v/pythontraining_withString.rar\n",
            "\n",
            "\n",
            "Would you like to replace the existing file /content/w2v/pythontraining_withString_X\n",
            "337300692 bytes, modified on 2019-10-23 00:41\n",
            "with a new one\n",
            "337300692 bytes, modified on 2019-10-23 00:41\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit A\n",
            "\n",
            "Extracting  /content/w2v/pythontraining_withString_X                     \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNchbcQr_hTI",
        "outputId": "2594c668-0c54-4cc5-863d-704588f48b54"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.13.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.9.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "C8KsoN1P-03G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import myutils\n",
        "import sys\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import precision_score \n",
        "from sklearn.metrics import recall_score \n",
        "from sklearn.metrics import f1_score \n",
        "from sklearn.utils import class_weight\n",
        "from gensim.models import Word2Vec \n",
        "import wandb\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if use_cuda else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiCIUM-pmP6O",
        "outputId": "176c3ce6-c2bc-407b-e6d9-3c15885890f5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kDD_SZfM_7Rg"
      },
      "outputs": [],
      "source": [
        "#paramerters for filtering and creation of samples\n",
        "mode='sql'\n",
        "progress = 0\n",
        "count = 0\n",
        "restriction = [20000, 5, 6, 10]\n",
        "step = 5\n",
        "full_length = 200\n",
        "mode_param = str(step)+\"_\"+str(full_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5q_JAclsAXWo"
      },
      "outputs": [],
      "source": [
        "#parameters for w2v model\n",
        "mincount = 5000 #minimum time a word has to appear in the corpus to be in the w2vec model\n",
        "iterationen = 300  #training iterations for the w2v model\n",
        "s = 200 #d\n",
        "w = \"withString\"\n",
        "w2v_name = \"word2vec_\" + w + str(mincount) + \"-\" + str(iterationen) + \"-\" + str(s)\n",
        "w2v_model = 'w2v/'+ w2v_name + \".model\"\n",
        "\n",
        "w2v_model = Word2Vec.load(w2v_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoFUNpsrwJZD",
        "outputId": "217c90e4-5e05-4fe8-a1c9-a7104dfdb269"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meddiechen372\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zsOqMIwzEWDB"
      },
      "outputs": [],
      "source": [
        "# import json\n",
        "\n",
        "all_blocks = []\n",
        "# with open('data/plain_' + mode, 'r') as infile:\n",
        "  # data = json.load(infile)\n",
        "# allblocks = []\n",
        "# for r in data:\n",
        "#   progress = progress + 1\n",
        "#   for c in data[r]:\n",
        "    \n",
        "#     if \"files\" in data[r][c]:                      \n",
        "#       # if len(data[r][c][\"files\"]) > restriction[3]:\n",
        "#       #   # too many files\n",
        "#       #  continue\n",
        "      \n",
        "#       for f in data[r][c][\"files\"]:\n",
        "        \n",
        "#         # if len(data[r][c][\"files\"][f][\"changes\"]) >= restriction[2]:\n",
        "#         #   #too many changes in a single file\n",
        "#         #   continue\n",
        "        \n",
        "#         if not \"source\" in data[r][c][\"files\"][f]:\n",
        "#           #no sourcecode\n",
        "#           continue\n",
        "        \n",
        "#         if \"source\" in data[r][c][\"files\"][f]:\n",
        "#           sourcecode = data[r][c][\"files\"][f][\"source\"]                          \n",
        "#           # if len(sourcecode) > restriction[0]:\n",
        "#           #   #sourcecode is too long\n",
        "#           #   continue\n",
        "          \n",
        "#           allbadparts = []\n",
        "          \n",
        "#           for change in data[r][c][\"files\"][f][\"changes\"]:\n",
        "#                 #get the modified or removed parts from each change that happened in the commit                  \n",
        "#                 badparts = change[\"badparts\"]\n",
        "#                 count = count + len(badparts)\n",
        "#                 # if len(badparts) > restriction[1]:\n",
        "#                 #   #too many modifications in one change\n",
        "#                 #   break\n",
        "                 \n",
        "                \n",
        "#                 for bad in badparts:\n",
        "#                   #check if they can be found within the file\n",
        "#                   pos = myutils.findposition(bad,sourcecode)\n",
        "#                   if not -1 in pos:\n",
        "#                       allbadparts.append(bad)\n",
        "#                 # if (len(allbadparts) > restriction[4]):\n",
        "#                 #   # too many bad positions in the file\n",
        "#                 #   break\n",
        "#           if(len(allbadparts) > 0):\n",
        "#             # if len(allbadparts) < restriction[2]:\n",
        "#               # find the positions of all modified parts\n",
        "#               positions = myutils.findpositions(allbadparts,sourcecode)\n",
        "\n",
        "#               #get the file split up in samples\n",
        "#               blocks = myutils.getblocks(sourcecode, positions, step, full_length)\n",
        "              \n",
        "#               for b in blocks:\n",
        "#                   #each is a tuple of code and label\n",
        "#                   allblocks.append(b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XHepG1nwMWBF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchtext.transforms import ToTensor, PadTransform\n",
        "import random\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, allblocks ,data_split='train', transform=None, target_transform=None):\n",
        "    self.allblocks = allblocks \n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "    self.data_split=data_split\n",
        "  \n",
        "    keys = []\n",
        "    for i in range(len(self.allblocks)):\n",
        "      keys.append(i)\n",
        "    random.shuffle(keys)\n",
        "    cutoff = round(0.7 * len(keys)) #     70% for the training set\n",
        "    cutoff2 = round(0.85 * len(keys)) #   15% for the validation set and 15% for the final test set\n",
        "    self.keystrain = keys[:cutoff]\n",
        "    self.keysvalid = keys[cutoff:cutoff2]\n",
        "    self.keystest = keys[cutoff2:]\n",
        "\n",
        "    default_idx = self.keystrain[0]\n",
        "    block = self.allblocks[default_idx]\n",
        "    code = block[0]\n",
        "    self.default_token = myutils.getTokens(code)\n",
        "\n",
        "  def __len__(self):\n",
        "    if self.data_split == 'train': \n",
        "      return len(self.keystrain)\n",
        "    elif self.data_split == 'valid':\n",
        "      return len(self.keysvalid)\n",
        "    elif self.data_split == 'test': \n",
        "      return len(self.keystest)\n",
        "    else:\n",
        "      print('Invalid split')\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    word_vectors = w2v_model.wv\n",
        "    if self.data_split == 'train': \n",
        "      key_idx = self.keystrain[idx]\n",
        "    elif self.data_split == 'valid':\n",
        "      key_idx = self.keysvalid[idx]\n",
        "    elif self.data_split == 'test':\n",
        "      key_idx = self.keystest[idx]\n",
        "    block = self.allblocks[key_idx]\n",
        "    code = block[0]\n",
        "    token = myutils.getTokens(code) #get all single tokens from the snippet of code\n",
        "    if(len(token) == 0): \n",
        "      print(len(token))\n",
        "      token = self.default_token\n",
        "\n",
        "    vectorlist = []\n",
        "    if block[1] == 1: \n",
        "      label = 0 \n",
        "    else: \n",
        "      label = 1\n",
        "    for t in token: #convert all tokens into their word2vec vector representation\n",
        "      if t in word_vectors.vocab and t != \" \":\n",
        "        word_vector = w2v_model[t]\n",
        "        vectorlist.append(word_vector) \n",
        "    vectorlist = torch.tensor(vectorlist)\n",
        "    if self.transform:\n",
        "      vectorlist = self.transform(vectorlist)\n",
        "    if self.target_transform:\n",
        "      label = self.target_transform(label)\n",
        "    return vectorlist, label \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "36IgdIZUteuH"
      },
      "outputs": [],
      "source": [
        "# from torchtext.transforms import ToTensor, PadTransform\n",
        "\n",
        "# train_dataset = MyDataset(\n",
        "#     allblocks=allblocks,\n",
        "#     data_split='train',\n",
        "# )\n",
        "# valid_dataset = MyDataset(\n",
        "#     allblocks=allblocks,\n",
        "#     data_split='valid'\n",
        "# )\n",
        "# test_dataset = MyDataset(\n",
        "#     allblocks=allblocks,\n",
        "#     data_split='test'\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_path = '/content/drive/MyDrive/data'\n",
        "# isFiltered = False \n",
        "# name = '_filtered' if isFiltered else '' \n",
        "# torch.save(train_dataset, f'{data_path}/train_data_{mode}{name}.pth')\n",
        "# torch.save(valid_dataset, f'{data_path}/valid_data_{mode}{name}.pth')\n",
        "# torch.save(test_dataset, f'{data_path}/test_data_{mode}{name}.pth')"
      ],
      "metadata": {
        "id": "kfNdCdVPoxck"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_dataset = torch.load(f'{data_path}/train_data_{mode}{name}.pth')\n",
        "# valid_dataset = torch.load(f'{data_path}/valid_data_{mode}{name}.pth')\n",
        "# test_dataset = torch.load(f'{data_path}/test_data_{mode}{name}.pth')"
      ],
      "metadata": {
        "id": "tONl2Kwxo5cD"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yMUbdH6lIBOe"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class MyCollate:\n",
        "    def __init__(self, pad_idx):\n",
        "        self.pad_idx = pad_idx\n",
        "        \n",
        "    \n",
        "    def __call__(self, batch):\n",
        "      source = []\n",
        "      target = []\n",
        "      for i in range(len(batch)):\n",
        "        if batch[i][0].shape[0] != 0:\n",
        "          source.append(batch[i][0]) \n",
        "          target.append(batch[i][1])\n",
        "\n",
        "      for i in range(len(batch) - len(source)):\n",
        "        source.append(source[-1])\n",
        "        target.append(target[-1])\n",
        "      \n",
        "      source = pad_sequence(source, batch_first=True, padding_value = self.pad_idx) \n",
        "      return source, target "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZNZJPHN6LMUs"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader \n",
        "\n",
        "def get_data_loader(dataset, batch_size, num_workers=0, shuffle=True, pin_memory=True): #increase num_workers according to CPU\n",
        "    pad_idx = 0 \n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size = batch_size, \n",
        "        num_workers = num_workers,\n",
        "        shuffle=shuffle,\n",
        "        pin_memory=pin_memory, \n",
        "        collate_fn = MyCollate(pad_idx=pad_idx)\n",
        "    ) \n",
        "    return loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vua3uGG_NeaD"
      },
      "outputs": [],
      "source": [
        " \n",
        "# train_loader = get_data_loader(train_dataset, batch_size=batch_size )\n",
        "# valid_loader = get_data_loader(valid_dataset, batch_size=batch_size)\n",
        "# test_loader = get_data_loader(test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YNnxQiziP1XZ"
      },
      "outputs": [],
      "source": [
        "class MyGRU(nn.Module):\n",
        "  def __init__(self, hidden_size=200, num_layers=1, bidirectional=False, dropout=0.2):\n",
        "    super(MyGRU, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = w2v_model\n",
        "    self.num_layers = num_layers\n",
        "    self.bidirectional = bidirectional\n",
        "    self.gru = nn.GRU(\n",
        "        hidden_size,\n",
        "        hidden_size,\n",
        "        dropout=dropout,\n",
        "        batch_first=True, \n",
        "        num_layers=self.num_layers,\n",
        "        bidirectional=self.bidirectional\n",
        "    )\n",
        "    self.out = nn.Linear(hidden_size, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, input, hidden):\n",
        "    hidden = hidden.cuda()\n",
        "    output, hidden = self.gru(input, hidden )\n",
        "    output = self.out(output)\n",
        "    output = self.sigmoid(output)\n",
        "    return output, hidden\n",
        "  \n",
        "  def initHidden(self, batch_size=1):\n",
        "    hidden = torch.zeros(2 if self.bidirectional else 1 * self.num_layers, batch_size ,self.hidden_size).to(device)\n",
        "    return hidden \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLSTM(nn.Module):\n",
        "  def __init__(self, hidden_size=200, num_layers=1, bidirectional=False, dropout=0.2):\n",
        "    super(MyLSTM, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = w2v_model\n",
        "    self.num_layers = num_layers\n",
        "    self.bidirectional = bidirectional\n",
        "    self.lstm = nn.LSTM(\n",
        "        hidden_size,\n",
        "        hidden_size,\n",
        "        dropout=dropout,\n",
        "        batch_first=True, \n",
        "        num_layers=self.num_layers,\n",
        "        bidirectional=self.bidirectional\n",
        "    )\n",
        "    self.out = nn.Linear(hidden_size, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, input, hidden):\n",
        "    output, hidden = self.lstm(input, hidden)\n",
        "    output = self.out(output)\n",
        "    output = self.sigmoid(output)\n",
        "    return output, hidden\n",
        "  \n",
        "  def initHidden(self, batch_size=1):\n",
        "    h0 = torch.zeros(2 if self.bidirectional else 1 * self.num_layers, batch_size ,self.hidden_size).to(device)\n",
        "    c0 = torch.zeros(2 if self.bidirectional else 1 * self.num_layers, batch_size ,self.hidden_size).to(device)\n",
        "    return h0, c0 \n",
        "    "
      ],
      "metadata": {
        "id": "XtwOqeYw2Sbx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fnk6ty7oU-pE"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import time\n",
        "print_every = 1000\n",
        "plot_every = 50000\n",
        "\n",
        "def timeSince(since):\n",
        "  now = time.time()\n",
        "  s = now - since\n",
        "  m = math.floor(s/60)\n",
        "  s -= m * 60\n",
        "  return f'{m}m {math.floor(s)}s' \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_binary_cross_entropy(output, target, weights=None):\n",
        "    # print(output, target)\n",
        "    if weights is not None:\n",
        "        assert len(weights) == 2\n",
        "        loss = weights[1] * (target * torch.log(output)) + \\\n",
        "               weights[0] * ((1 - target) * torch.log(1 - output))\n",
        "    else:\n",
        "        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
        "\n",
        "    return torch.neg(torch.mean(loss))"
      ],
      "metadata": {
        "id": "67L3u1L5TaZo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "sTANYdyqup0J"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torchmetrics import F1Score, Precision, Recall\n",
        "\n",
        "def evaluate(model, loader, batch_size, class_weights):\n",
        "  targets = torch.tensor([]).cuda() \n",
        "  preds = torch.tensor([]).cuda() \n",
        "  start = time.time()\n",
        "  all_losses = []\n",
        "\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    print_count = 0 \n",
        "    for iter, (input , labels) in enumerate(loader):\n",
        "\n",
        "      hidden = model.initHidden(batch_size=batch_size)\n",
        "      label_tensor = torch.tensor(labels).to(device)\n",
        "      input = input.to(device)\n",
        "\n",
        "      targets = torch.cat((targets, torch.tensor(label_tensor)))\n",
        "      output, hidden = model(input, hidden)\n",
        "      final_output = output[:, -1, :].T\n",
        "\n",
        "      loss = weighted_binary_cross_entropy(final_output , label_tensor, weights=class_weights)\n",
        "      all_losses.append(loss)\n",
        "      preds = torch.cat((preds, final_output), 1)\n",
        "\n",
        "    eval_loss = torch.mean(torch.tensor(all_losses))\n",
        "    preds = torch.squeeze(preds)\n",
        "    targets = targets.int()\n",
        "    \n",
        "  preds = torch.tensor(preds).to(device)\n",
        "  targets = torch.tensor(targets).to(device)\n",
        "  f1 = F1Score(num_classes=1).to(device)\n",
        "\n",
        "  precision = Precision(num_classes=1).to(device)\n",
        "  recall = Recall(num_classes=1).to(device)\n",
        "\n",
        "  f1_score = f1(preds, targets)\n",
        "  precision_score = precision(preds, targets)\n",
        "  recall_score = recall(preds, targets)\n",
        "\n",
        "  wandb.log({\n",
        "    'f1 score': f1_score,\n",
        "    'precision score': precision_score,\n",
        "    'recall score': recall_score,\n",
        "    'eval loss': eval_loss\n",
        "  })\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "68E3FnpixMZO"
      },
      "outputs": [],
      "source": [
        "# evaluate(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OBc6y15YU3kv"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "def train_mini_batch(model, input_tensor, label_tensor, batch_size, optimizer, class_weights):\n",
        "  hidden = model.initHidden(batch_size=batch_size)\n",
        "  model.zero_grad()\n",
        "  label_tensor = torch.tensor([label_tensor]).to(device)\n",
        "  input = input_tensor.to(device)\n",
        "  output, hidden = model(input, hidden)\n",
        "  final_output = output[:, -1, :].T\n",
        "  loss = weighted_binary_cross_entropy(final_output , label_tensor, weights=class_weights)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return final_output, loss.item()\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, loader, batch_size, optimizer, class_weights):\n",
        "  all_losses = []\n",
        "  for iter, (input_tensor, label_tensor) in enumerate(loader):\n",
        "    preds, loss = train_mini_batch(model, input_tensor, label_tensor, batch_size, optimizer, class_weights)\n",
        "    all_losses.append()\n",
        "    \n",
        "  wandb.log({'train_loss': torch.mean(torch.tensor(all_losses))})\n"
      ],
      "metadata": {
        "id": "_K47FhFx9_w8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getModel(architecture):\n",
        "  if architecture == 'GRU':\n",
        "    return MyGRU().to(device)\n",
        "  else:\n",
        "    return MyLSTM().to(device) "
      ],
      "metadata": {
        "id": "8bmpj6H2qKmm"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "qpLk9VpEkY4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75615296-5910-49c5-c640-3570c0b35fbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ],
      "source": [
        "model = getModel('LSTM') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrFkBLvQFLd_",
        "outputId": "f6189742-8d22-4eb5-a686-74197f8be52a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "datasets = ['sql', 'xss', 'xsrf', 'path_disclosure', 'open_redirect', 'command_injection', 'remote_code_execution']\n",
        "architectures = ['LSTM', 'GRU']\n",
        "data_path = '/content/drive/MyDrive/data'\n",
        "def run():\n",
        "  conf = dict(\n",
        "    learning_rate = 0.0005,\n",
        "    infra = 'Google colab',\n",
        "    dataset = '',\n",
        "    architecure = '',\n",
        "    log_interval=1000,\n",
        "    epochs = 10,\n",
        "    batch_size=128, \n",
        "    full_length = 200,\n",
        "    step = 5,\n",
        "    word_min_count = 5000,\n",
        "    iterationen = 300,\n",
        "    hidden_size = 200,\n",
        "    with_string = 'withString',\n",
        "    seed = 42,\n",
        "  )\n",
        "\n",
        "  for dataset in datasets:   \n",
        "    print(f'current dataset: {dataset}')\n",
        "    conf['dataset'] = dataset\n",
        "\n",
        "    train_dataset = torch.load(f'{data_path}/train_data_{conf[\"dataset\"]}.pth')\n",
        "    train_loader = get_data_loader(train_dataset, batch_size=conf['batch_size'])\n",
        "\n",
        "    valid_dataset = torch.load(f'{data_path}/valid_data_{conf[\"dataset\"]}.pth')\n",
        "    valid_loader = get_data_loader(valid_dataset, batch_size=conf['batch_size'])\n",
        "\n",
        "    # test_dataset = torch.load(f'{data_path}/test_data_{conf[\"dataset\"]}.pth')\n",
        "    # test_loader = get_data_loader(test_dataset, batch_size=conf['batch_size'])\n",
        "\n",
        "\n",
        "    print('Calulating class weigths...')\n",
        "    y = np.concatenate([label for item, label in train_loader])\n",
        "    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
        "    print(f'{dataset} dataset class weights: {class_weights}')\n",
        "\n",
        "    for architecture in architectures:\n",
        "      print(f'current architecture: {architecture}')\n",
        "      conf['architecture'] = architecture\n",
        "      wandb.init(\n",
        "        project='Thesis',\n",
        "        notes=f'Tweak baseline' ,\n",
        "        tags=[architecture],\n",
        "        config=conf\n",
        "\n",
        "      )\n",
        "      model = getModel(architecture)\n",
        "      optimizer = optim.Adam(model.parameters(), lr=conf['learning_rate'],  weight_decay=0)\n",
        "      wandb.watch(model, log='all')\n",
        "\n",
        "      for i in range(conf['epochs']):\n",
        "        train(model, train_loader , conf.batch_size, optimizer, class_weights)\n",
        "        evaluate(model, valid_loader, conf.batch_size, class_weights)\n",
        "      \n"
      ],
      "metadata": {
        "id": "Hw8AY44iLyVY"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609,
          "referenced_widgets": [
            "14f283c7d9af47089c61d3c04888c6c2",
            "77bfcb151a954cd49c0f754bac5676fe",
            "599b6b0f4a9443609913b2d89e4a9b83",
            "c655f189175a4d4b830ec2f4b262979a",
            "02422e952b0f42fdb5fde1c67fa7d153",
            "8ae1eac33ba8463e9453a51f4e9cee89",
            "2f12b337e2a0462c971ca901d2fde9a3",
            "4bab1408d0b94dd6b999c738e2d67c99"
          ]
        },
        "id": "5lXAPefhzJOT",
        "outputId": "4a37d2d9-feac-4898-e682-2a7bfb0c93b5"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current dataset: sql\n",
            "Calulating class weigths...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sql dataset class weights: [0.56109203 4.59218705]\n",
            "current architecture: LSTM\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:3setrcau) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14f283c7d9af47089c61d3c04888c6c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">hearty-terrain-6</strong>: <a href=\"https://wandb.ai/eddiechen372/thesis/runs/3setrcau\" target=\"_blank\">https://wandb.ai/eddiechen372/thesis/runs/3setrcau</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220920_090214-3setrcau/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:3setrcau). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220920_090525-1r3wdgbo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/eddiechen372/thesis/runs/1r3wdgbo\" target=\"_blank\">dainty-cherry-7</a></strong> to <a href=\"https://wandb.ai/eddiechen372/thesis\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-ec9775ede022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-74-a2814a0cac11>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'epochs'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.load(f'{data_path}/train_data_sql.pth')\n",
        "train_loader = get_data_loader(train_dataset, batch_size=128)\n",
        "label_batches = [label for item, label in train_loader]\n",
        "\n",
        "y = np.concatenate(label_batches)\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "jVki2jhmCwYG",
        "outputId": "29c17db9-478d-4031-80bf-c66b0b320997"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-f708720ebc7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{data_path}/train_data_sql.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabel_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-f708720ebc7d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{data_path}/train_data_sql.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabel_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    679\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-1120d53e1467>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#convert all tokens into their word2vec vector representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mword_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mvectorlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mvectorlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m                 )\n\u001b[0;32m-> 1422\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method will be removed in 4.0.0, use self.wv.__contains__() instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "array = []\n",
        "train_loader = get_data_loader(train_dataset, batch_size=128)\n",
        "for item, label in train_loader:\n",
        "  \n",
        "  print(label.shape)\n",
        "  array.append(label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "HtC_vRtfJ_B1",
        "outputId": "9fd7b92d-d326-447b-fca0-eae53048e1f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f6c19e77eeeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_data_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4AG3IDlPKvI3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNBb8+/JvyetSNoPSukG/OH",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14f283c7d9af47089c61d3c04888c6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77bfcb151a954cd49c0f754bac5676fe",
              "IPY_MODEL_599b6b0f4a9443609913b2d89e4a9b83"
            ],
            "layout": "IPY_MODEL_c655f189175a4d4b830ec2f4b262979a"
          }
        },
        "77bfcb151a954cd49c0f754bac5676fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02422e952b0f42fdb5fde1c67fa7d153",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8ae1eac33ba8463e9453a51f4e9cee89",
            "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "599b6b0f4a9443609913b2d89e4a9b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f12b337e2a0462c971ca901d2fde9a3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bab1408d0b94dd6b999c738e2d67c99",
            "value": 1
          }
        },
        "c655f189175a4d4b830ec2f4b262979a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02422e952b0f42fdb5fde1c67fa7d153": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae1eac33ba8463e9453a51f4e9cee89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f12b337e2a0462c971ca901d2fde9a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bab1408d0b94dd6b999c738e2d67c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}